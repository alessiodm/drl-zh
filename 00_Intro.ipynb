{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "\n",
    "Welcome to **Deep Reinforcement Learning: Zero to Hero!** ðŸš€ This is a hands-on course designed to\n",
    "take you through the fascinating world of Deep Reinforcement Learning (DRL).\n",
    "\n",
    "In this series, you will write the most recent and popular _model-free_ RL algorithms from scratch.\n",
    "We'll start with the fundamentals, replicating the\n",
    "[2013 breakthrough](https://arxiv.org/abs/1312.5602) that taught an agent to play Atari games from\n",
    "pixels. Then, we'll move on to landing a lunar module on the Moon using PPO, a state-of-the-art\n",
    "algorithm recently applied to fine-tune large language models (LLMs) such as ChatGPT and Google\n",
    "Gemini.\n",
    "\n",
    "<div style=\"width: 50%\">\n",
    "  <img src=\"assets/00_Intro_DQN_Atari.png\">\n",
    "</div>\n",
    "\n",
    "Later in the course, we'll dive into more advanced and cutting-edge topics to build even more\n",
    "capable and intelligent agents, including exploration with random network distillation (and solve\n",
    "`MiniGrid-DoorKey-16x16` with no memory), multi-agent RL, AlphaZero and Monte Carlo Tree Search,\n",
    "model-based RL, RLHF, and more!\n",
    "\n",
    "**NOTE**: The algorithms implemented in these lectures are optimized for _learning_. They retain the\n",
    "spirit and key details of the original algorithms but avoid unnecessary code complexity (e.g.,\n",
    "manually moving tensors between GPU and CPU) to keep the focus on the core concepts.\n",
    "\n",
    "## Why is Reinforcement Learning So Exciting?\n",
    "\n",
    "Deep Reinforcement Learning can feel less accessible than other areas of AI, but it's also one of\n",
    "the most intriguing. This is because it tackles a fundamentally different and more autonomous\n",
    "learning problem: **how can an agent learn to make optimal decisions by interacting with an\n",
    "environment?**\n",
    "\n",
    "Unlike other machine learning paradigms, the agent isn't given a dataset of \"correct\" answers.\n",
    "Instead, it learns through trial and error, guided only by a sparse **reward signal**. This is much\n",
    "closer to how humans and animals learn. This unique, interactive learning process is what allows RL\n",
    "agents to achieve superhuman performance in complex games like Go and to solve challenging control\n",
    "problems like robotic manipulation.\n",
    "\n",
    "<div style=\"width:30%\">\n",
    "  <img src=\"assets/00_Intro_robot.png\">\n",
    "  <br>\n",
    "  <small>From <a href=\"https://openai.com/research/solving-rubiks-cube\">OpenAI</a></small>\n",
    "</div>\n",
    "\n",
    "### Where Does RL Fit in AI?\n",
    "\n",
    "AI visionary and Turing Award winner Yann LeCun proposed a powerful analogy to contextualize\n",
    "different types of learning in AI, which has come to be known as \"LeCun's Cake\" or \"LeCake.\"\n",
    "\n",
    "He described the landscape of machine learning as a cake:\n",
    "\n",
    "- **The Cake**: **Unsupervised (or Self-Supervised) Learning** is the bulk of the cake. It\n",
    "  represents the vast majority of learning, where models learn the underlying structure of data\n",
    "  without explicit labels.\n",
    "- **The Icing**: **Supervised Learning (and Fine-Tuning)** is the icing on the cake. It's a thinner\n",
    "  layer because it relies on labeled data, which is far less abundant than unlabeled data.\n",
    "- **The Cherry**: **Reinforcement Learning** is the cherry on top. The reward signal in RL provides\n",
    "  very little information compared to the rich, high-bandwidth data used in supervised and\n",
    "  unsupervised learning. As LeCun puts it, it's like \"a bit of information per action.\"\n",
    "\n",
    "<br>\n",
    "<div style=\"width: 25%\">\n",
    "  <img src=\"assets/00_Intro_lecake.png\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "This analogy highlights both the power and the challenge of RL. While the learning signal is sparse,\n",
    "the ability to learn from it is the key to creating truly intelligent, autonomous agents that can\n",
    "navigate the complexities of the real world. This course aims to give you the tools to build that\n",
    "\"cherry.\"\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To make the most out of this course, you should have the following:\n",
    "\n",
    "- **Proficiency in Python**: You should be comfortable with Python programming, including concepts\n",
    "  like classes, data structures (lists, dictionaries), and general control flow.\n",
    "- **Familiarity with Deep Learning & PyTorch**: You should understand the fundamentals of deep\n",
    "  learning, such as neural networks, activation functions, and gradient descent. This course uses\n",
    "  **PyTorch**, so prior experience with it is highly beneficial.\n",
    "- **Mathematical Foundations (for theory)**: To fully grasp the theory behind the algorithms (which\n",
    "  is optional but recommended), a solid understanding of basic **calculus** (derivatives), **linear\n",
    "  algebra** (vectors, matrices), **statistics**, and **probability theory** is required.\n",
    "\n",
    "<div>\n",
    "  <div style=\"width: 10%;display:inline-block;background-color:white;\">\n",
    "    <img src=\"assets/00_Intro_nn.svg\">\n",
    "  </div>\n",
    "  <div style=\"margin-left:50px;width:10%;margin-top:20px;display:inline-block;vertical-align:center\">\n",
    "    <img src=\"assets/00_Intro_python.png\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "Don't worry if you need a refresher! There are fantastic resources available. For Python, consider\n",
    "the [official tutorial](https://docs.python.org/3/tutorial/appetite.html) or\n",
    "[W3Schools](https://www.w3schools.com/python/). For deep learning, a great resource is the\n",
    "[Deep Learning Specialization](https://www.deeplearning.ai/courses/deep-learning-specialization/)\n",
    "from DeepLearning.AI.\n",
    "\n",
    "## Credits\n",
    "\n",
    "This series wouldn't be possible without all the resources from which I learnt and that I actively\n",
    "consulted myself. In fact, there is very little novelty in this repository! My only hope is that\n",
    "this step by step guide of building up algorithms and theory from first principles and ground up\n",
    "will help more people to approach Deep RL in a practical way. Below you find all the resources that\n",
    "effectively contributed to this material.\n",
    "\n",
    "## Resources\n",
    "\n",
    "[**Reinforcement Learning: An Introduction (2nd Edition) 2020**](http://incompleteideas.net/book/the-book-2nd.html):\n",
    "The bible of Reinforcement Learning, everybody should read this book to grasp the foundations.\n",
    "\n",
    "**[Foundations of Deep RL Lectures](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjNymuBM9RdmB3Z9N5-0IlY0)\n",
    "by Peter Abbeel**: A comprehensive and theoretically complete basic introductions to Deep\n",
    "Reinforcement Learning by one of the biggest experts in the field. Part of this work explicitly\n",
    "references these lectures.\n",
    "\n",
    "**[Neural Networks: Zero to Hero](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n",
    "by Andrej Karpathy**: An introduction to deep neural networks from their foundations to advanced\n",
    "topics, starting from first principles the way the only Andrej (one of my heros!) can do! I\n",
    "shamelessly copied the title!\n",
    "\n",
    "**[Deep Reinforcement Learning Udacity Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)**:\n",
    "A Udacity nano-degree that I took, and helped me significantly in gaining experience and practice\n",
    "Deep RL. Some of the algorithms in this course are adaptation of algorithms I wrote for the exams of\n",
    "this course (and I'll link them on GitHub).\n",
    "\n",
    "**[OpenAI Spinning Up](https://spinningup.openai.com/en/latest/index.html)**: Educational resource\n",
    "produced by OpenAI that makes it easier to learn about deep reinforcement learning.\n",
    "\n",
    "**[Hugging Face Deep RL Course](https://huggingface.co/learn/deep-rl-course/en/unit0/introduction)**:\n",
    "Another incredibly easy to digest and pedagogic online resource about Deep RL! Thanks Hugging Face!\n",
    "\n",
    "**[CS-285 Berkeley](https://rail.eecs.berkeley.edu/deeprlcourse-fa22/)**: Course on Deep RL by the\n",
    "Berkeley University.\n",
    "\n",
    "[**CleanRL**](https://docs.cleanrl.dev/): Single-file implementations of most Deep RL algorithms,\n",
    "benchmarked and clean code.\n",
    "\n",
    "[**Deep RL Doesn't Work Yet**](https://www.alexirpan.com/2018/02/14/rl-hard.html): An incredible\n",
    "blog post about the challenges that Deep Reinforcement Learning faces today, a must read.\n",
    "\n",
    "[**Stable-Baselines3**](https://stable-baselines3.readthedocs.io/): Reliable implementations of RL\n",
    "algorithms in PyTorch.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlzh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
