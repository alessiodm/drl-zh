{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next - A Bridge to Advanced Topics\n",
    "\n",
    "Congratulations on making it through the foundations of Deep Reinforcement Learning! You've built\n",
    "some of the most influential algorithms from scratch, from DQN to PPO, and have developed a solid\n",
    "base for tackling even more complex challenges. The journey so far has equipped you with the core\n",
    "principles needed to understand the current landscape of RL.\n",
    "\n",
    "<br>\n",
    "<div style=\"width:20%; margin:auto;\">\n",
    "  <img src=\"assets/07_Next_robot.png\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Now, you stand at a bridge to the frontiers of the field. The following chapters delve into\n",
    "specialized and advanced topics. Unlike the foundational section, **there is no required order\n",
    "here**. Feel free to jump into the topics that excite you the most. Each notebook is a\n",
    "self-contained exploration of a fascinating subfield.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next? Your Path Forward\n",
    "\n",
    "Here’s a look at the advanced topics waiting for you. Pick your passion and dive in!\n",
    "\n",
    "- **Exploration and Curiosity (`08_EXPL.ipynb`)**: What happens when rewards are rare? This notebook\n",
    "  tackles the challenge of sparse rewards by implementing an _intrinsic curiosity module_. You'll\n",
    "  use **Random Network Distillation (RND)** to encourage an agent to explore its environment out of\n",
    "  a sense of novelty, allowing it to solve difficult tasks like navigating the MiniGrid world.\n",
    "\n",
    "- **Multi-Agent Reinforcement Learning (`09_MARL.ipynb`)**: Move beyond single-agent scenarios and\n",
    "  into a world of cooperation and competition. You'll explore the unique challenges of MARL, such as\n",
    "  non-stationarity, and implement the **Multi-Agent DDPG (MA-DDPG)** algorithm using the paradigm of\n",
    "  Centralized Training with Decentralized Execution (CTDE).\n",
    "\n",
    "- **Imitation Learning (`10_IL.ipynb`)**: Sometimes, the easiest way to teach an agent is to show it\n",
    "  how an expert behaves. In this notebook, you’ll learn how to train an agent by imitating expert\n",
    "  demonstrations. You'll implement **Behavioral Cloning (BC)**, treat it as a supervised learning\n",
    "  problem, and discuss its core challenges like covariate shift.\n",
    "\n",
    "- **Monte Carlo Tree Search & AlphaZero (`11_MCTS.ipynb`)**: Uncover the secrets behind the\n",
    "  algorithms that mastered Go and chess. You’ll start by building a **Monte Carlo Tree Search\n",
    "  (MCTS)** agent from scratch to play classic games. Then, you'll level up by implementing the\n",
    "  legendary **AlphaZero** algorithm, which combines MCTS with deep neural networks and self-play.\n",
    "\n",
    "- **Productionizing RL (`12_PROD.ipynb`)**: Bridge the gap between theory and real-world\n",
    "  application. This notebook equips you with the essential tools for making your agents\n",
    "  production-ready. You’ll learn about experiment tracking with **Tensorboard**, parallelization\n",
    "  with **Ray**, and automated hyperparameter tuning with **Optuna**.\n",
    "\n",
    "- **Model-Based Reinforcement Learning (`13_MBRL.ipynb`)**: Why learn from the real world when you\n",
    "  can learn from a simulated one? This notebook introduces you to **Model-Based RL**, where the\n",
    "  agent first learns the dynamics of the environment. You'll build a version of the **Model-Based\n",
    "  Policy Optimization (MBPO)** algorithm to see how a learned world model can drastically improve\n",
    "  sample efficiency.\n",
    "\n",
    "- **Reinforcement Learning with Human Feedback (`14_RLHF.ipynb`)**: Step into the world of Large\n",
    "  Language Models! This notebook demystifies the process of **RLHF**, the technique used to align\n",
    "  models like ChatGPT and Gemini with human values. You'll implement a simplified RLHF pipeline to\n",
    "  fine-tune a small LLM, guiding it to generate responses preferred by humans.\n",
    "\n",
    "---\n",
    "\n",
    "Each of these notebooks offers a unique perspective on the power and breadth of Deep Reinforcement\n",
    "Learning. They represent active areas of research and application that are shaping the future of AI.\n",
    "Choose your adventure, and continue your journey from zero to hero. Happy learning!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
